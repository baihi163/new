import os
# --- ä¿®å¤ OMP: Error #15 ---
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import torch
import torchvision
import torchvision.transforms as T
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
from PIL import Image
import task5_dataset

# --- 1. å®šä¹‰æ¨¡å‹æ„å»ºå‡½æ•° ---
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

def get_model_instance_segmentation(num_classes):
    model = maskrcnn_resnet50_fpn(weights=None) 
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)
    return model

# --- 2. å®šä¹‰è½¬æ¢å‡½æ•° ---
def get_transform():
    return T.Compose([T.ToTensor()])

# --- 3. åŠ è½½æ¨¡å‹ ---
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
num_classes = 2

print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = get_model_instance_segmentation(num_classes)
model.load_state_dict(torch.load("mask_rcnn_model.pth", map_location=device))
model.to(device)
model.eval()
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

# --- 4. é¢„æµ‹ä¸å¯è§†åŒ– ---
# åŠ è½½æ•°æ®é›†çš„ä¸€å¼ å›¾ (æ¯”å¦‚ç¬¬ 0 å¼ )
dataset = task5_dataset.PennFudanDataset('PennFudanPed', transforms=get_transform())
img, _ = dataset[0] 

print("æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
with torch.no_grad():
    prediction = model([img.to(device)])

# è·å–é¢„æµ‹ç»“æœ
pred_masks = prediction[0]['masks']
pred_boxes = prediction[0]['boxes']
pred_scores = prediction[0]['scores']

# ç­›é€‰ç½®ä¿¡åº¦ > 0.5 çš„
keep = pred_scores > 0.5
pred_masks = pred_masks[keep]
pred_boxes = pred_boxes[keep]

print(f"âœ… æ£€æµ‹åˆ° {len(pred_boxes)} ä¸ªç›®æ ‡")

# ç»˜å›¾
img_np = img.mul(255).permute(1, 2, 0).byte().numpy()
plt.figure(figsize=(10, 10))

# 1. å…ˆç”»åŸå›¾
plt.imshow(img_np)
ax = plt.gca()

# 2. ç”» Mask (ä½¿ç”¨ RGBA å›¾å±‚æ–¹æ³•ï¼Œé¿å…å½¢çŠ¶æŠ¥é”™)
if len(pred_masks) > 0:
    H, W = img_np.shape[:2]
    # åˆå¹¶æ‰€æœ‰æ£€æµ‹åˆ°çš„ Mask
    combined_mask = np.zeros((H, W))
    for i in range(len(pred_masks)):
        mask = pred_masks[i, 0].cpu().numpy()
        combined_mask = np.maximum(combined_mask, mask)
    
    # åˆ›å»ºä¸€ä¸ªçº¢è‰²çš„ RGBA å›¾å±‚
    # å½¢çŠ¶: (H, W, 4) -> R, G, B, Alpha
    overlay = np.zeros((H, W, 4))
    overlay[:, :, 0] = 1.0  # çº¢è‰²é€šé“è®¾ä¸º 1 (æœ€å¤§)
    overlay[:, :, 1] = 0.0  # ç»¿è‰²é€šé“è®¾ä¸º 0
    overlay[:, :, 2] = 0.0  # è“è‰²é€šé“è®¾ä¸º 0
    
    # è®¾ç½®é€æ˜åº¦ï¼šMask > 0.5 çš„åœ°æ–¹é€æ˜åº¦ä¸º 0.5ï¼Œå…¶ä»–åœ°æ–¹å®Œå…¨é€æ˜(0)
    overlay[:, :, 3] = np.where(combined_mask > 0.5, 0.5, 0.0)
    
    # ç”»ä¸Šå»
    plt.imshow(overlay)

# 3. ç”» Box (é»„è‰²æ¡†)
for box in pred_boxes:
    box = box.cpu().numpy()
    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], 
                             linewidth=2, edgecolor='yellow', facecolor='none')
    ax.add_patch(rect)

plt.axis('off')
plt.title(f"Result: {len(pred_boxes)} Pedestrians Detected")
plt.show()

print("ğŸ‰ å¯è§†åŒ–å®Œæˆï¼çª—å£å·²å¼¹å‡ºã€‚")